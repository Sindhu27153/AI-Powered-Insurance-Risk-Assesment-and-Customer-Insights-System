{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1daf57c",
   "metadata": {},
   "source": [
    "### ğŸ§  Multilingual Insurance Document Translator\n",
    "#### Goal: Translate a single English insurance document (PDF) into multiple languages in one go.\n",
    "\n",
    "âœ… Features\n",
    "\n",
    "ğŸ“„ Extract text from PDF.\n",
    "\n",
    "ğŸŒ Select multiple target languages.\n",
    "\n",
    "ğŸ¤– Translate using Hugging Face Transformers.\n",
    "\n",
    "ğŸ“ Generate one translated PDF per language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb22ce3",
   "metadata": {},
   "source": [
    "#### 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c769af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: sentencepiece in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: fpdf in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pymupdf in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (1.25.5)\n",
      "Requirement already satisfied: filelock in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch sentencepiece fpdf pymupdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44628a3a",
   "metadata": {},
   "source": [
    "#### 2. Script to Translate English PDF to Multiple Languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b2bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Translating to Hindi...\n",
      "ğŸ” Translating to Tamil...\n",
      "ğŸ” Translating to Telugu...\n",
      "âœ… PDF saved for Hindi: Translated_Insurance_Policy_Hindi.pdf\n",
      "âœ… PDF saved for Tamil: Translated_Insurance_Policy_Tamil.pdf\n",
      "âœ… PDF saved for Telugu: Translated_Insurance_Policy_Telugu.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from fpdf import FPDF\n",
    "import textwrap\n",
    "from googletrans import Translator\n",
    "\n",
    "# Constants\n",
    "FONT_PATH = \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSans-Regular.ttf\"\n",
    "FONT_FAMILY = \"NotoSans\"\n",
    "DEFAULT_LANGUAGE = \"Hindi\"\n",
    "\n",
    "# Define supported languages with Google Translate codes\n",
    "SUPPORTED_LANGUAGES = {\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Tamil\": \"ta\",\n",
    "    \"Telugu\": \"te\",\n",
    "    \"Gujarati\": \"gu\",\n",
    "    \"Kannada\": \"kn\",\n",
    "    \"Bengali\": \"bn\",\n",
    "    \"Punjabi\": \"pa\",\n",
    "    \"Marathi\": \"mr\",\n",
    "    \"Malayalam\": \"ml\",\n",
    "    \"Urdu\": \"ur\",\n",
    "    \"Odia\": \"or\"\n",
    "}\n",
    "\n",
    "# Step 1: Extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")\n",
    "    return text\n",
    "\n",
    "# Step 2: Translate text to multiple languages\n",
    "def translate_text(text, target_languages):\n",
    "    translator = Translator()\n",
    "    translations = {}\n",
    "    for language in target_languages:\n",
    "        try:\n",
    "            lang_code = SUPPORTED_LANGUAGES[language]\n",
    "            print(f\"ğŸ” Translating to {language}...\")\n",
    "            translated = translator.translate(text, dest=lang_code)\n",
    "            translations[language] = translated.text\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error translating to {language}: {e}\")\n",
    "    return translations\n",
    "\n",
    "# Step 3: PDF generator that preserves alignment\n",
    "class UnicodePDF(FPDF):\n",
    "    def __init__(self, font_path, font_family, title=\"\"):\n",
    "        super().__init__()\n",
    "        if not os.path.isfile(font_path):\n",
    "            raise RuntimeError(f\"âŒ Font file not found: {font_path}\")\n",
    "        self.font_family = font_family\n",
    "        self.title = title  # Set title before add_page\n",
    "        self.add_font(font_family, '', font_path, uni=True)\n",
    "        self.add_page()\n",
    "        self.set_font(font_family, '', 12)\n",
    "        self.set_left_margin(10)\n",
    "        self.set_right_margin(10)\n",
    "\n",
    "    def header(self):\n",
    "        self.set_font(self.font_family, '', 16)\n",
    "        self.cell(0, 10, self.title, ln=True, align='C')\n",
    "        self.ln(10)\n",
    "        self.set_font(self.font_family, '', 12)\n",
    "\n",
    "    def add_multiline_text(self, text):\n",
    "        for paragraph in text.split(\"\\n\"):\n",
    "            wrapped = textwrap.fill(paragraph.strip(), width=90)\n",
    "            self.multi_cell(0, 8, wrapped)\n",
    "            self.ln(2)\n",
    "\n",
    "    def save(self, output_path):\n",
    "        self.output(output_path)\n",
    "\n",
    "# Step 4: Create the translated PDF\n",
    "def create_unicode_pdf(translated_text, language, output_path):\n",
    "    try:\n",
    "        pdf = UnicodePDF(FONT_PATH, FONT_FAMILY, f\"Translated Insurance Policy - {language}\")\n",
    "        pdf.add_multiline_text(translated_text)\n",
    "        pdf.save(output_path)\n",
    "        print(f\"âœ… PDF saved for {language}: {output_path}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Step 5: Orchestrate the process\n",
    "def main(pdf_path, selected_languages):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    translations = translate_text(text, selected_languages)\n",
    "    for language, translated_text in translations.items():\n",
    "        output_path = f\"Translated_Insurance_Policy_{language}.pdf\"\n",
    "        create_unicode_pdf(translated_text, language, output_path)\n",
    "\n",
    "# Step 6: Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    selected_languages = [\"Hindi\", \"Tamil\", \"Telugu\"] \n",
    "    valid_languages = [lang for lang in selected_languages if lang in SUPPORTED_LANGUAGES]\n",
    "\n",
    "    if valid_languages:\n",
    "        pdf_path = \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Dataset/Health_Insurance_Policy.pdf\"\n",
    "        main(pdf_path, valid_languages)\n",
    "    else:\n",
    "        print(\"âŒ No valid languages selected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e99c8eb",
   "metadata": {},
   "source": [
    "#### Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c1e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Translated_Insurance_Policy_Hindi.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Run on Hindi translated PDF\u001b[39;00m\n\u001b[32m     52\u001b[39m pdf_path = \u001b[33m\"\u001b[39m\u001b[33mD:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Translated_Insurance_Policy_Hindi.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m summary = \u001b[43msummarize_translated_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_lang_code\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhi\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ“„ à¤¹à¤¿à¤‚à¤¦à¥€ à¤¸à¤¾à¤°à¤¾à¤‚à¤¶:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, summary)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36msummarize_translated_pdf\u001b[39m\u001b[34m(pdf_path, original_lang_code)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msummarize_translated_pdf\u001b[39m(pdf_path, original_lang_code=\u001b[33m'\u001b[39m\u001b[33mhi\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     original_text = \u001b[43mextract_pdf_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ” Original Language Detected Text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, original_text[:\u001b[32m300\u001b[39m])  \u001b[38;5;66;03m# Preview\u001b[39;00m\n\u001b[32m     45\u001b[39m     english_text = translate_to_english(original_text)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mextract_pdf_text\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_pdf_text\u001b[39m(pdf_path):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     12\u001b[39m         reader = PyPDF2.PdfReader(file)\n\u001b[32m     13\u001b[39m         full_text = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Translated_Insurance_Policy_Hindi.pdf'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from googletrans import Translator\n",
    "import PyPDF2\n",
    "\n",
    "# Initialize translation and summarization tools\n",
    "translator = Translator()\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Step 1: Extract text from translated language PDF\n",
    "def extract_pdf_text(pdf_path):\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        full_text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                full_text += text\n",
    "        return full_text\n",
    "\n",
    "# Step 2: Translate to English\n",
    "def translate_to_english(text):\n",
    "    translated = translator.translate(text, dest='en')\n",
    "    return translated.text\n",
    "\n",
    "# Step 3: Summarize in English\n",
    "def summarize_text(text):\n",
    "    max_chunk = 1000\n",
    "    summary = \"\"\n",
    "    for i in range(0, len(text), max_chunk):\n",
    "        chunk = text[i:i+max_chunk]\n",
    "        result = summarizer(chunk, max_length=130, min_length=30, do_sample=False)\n",
    "        summary += result[0]['summary_text'] + \"\\n\"\n",
    "    return summary\n",
    "\n",
    "# Step 4: Optional - Translate summary back to original language (e.g., Hindi)\n",
    "def translate_back_to_language(text, dest_lang='hi'):\n",
    "    translated = translator.translate(text, dest=dest_lang)\n",
    "    return translated.text\n",
    "\n",
    "# Full pipeline\n",
    "def summarize_translated_pdf(pdf_path, original_lang_code='hi'):\n",
    "    original_text = extract_pdf_text(pdf_path)\n",
    "    print(\"ğŸ” Original Language Detected Text:\\n\", original_text[:300])  # Preview\n",
    "\n",
    "    english_text = translate_to_english(original_text)\n",
    "    english_summary = summarize_text(english_text)\n",
    "\n",
    "    final_summary = translate_back_to_language(english_summary, dest_lang=original_lang_code)\n",
    "    return final_summary\n",
    "\n",
    "# Run on Hindi translated PDF\n",
    "pdf_path = \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Translated_Insurance_Policy_Hindi.pdf\"\n",
    "summary = summarize_translated_pdf(pdf_path, original_lang_code='hi')\n",
    "\n",
    "print(\"\\nğŸ“„ à¤¹à¤¿à¤‚à¤¦à¥€ à¤¸à¤¾à¤°à¤¾à¤‚à¤¶:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec0a6d",
   "metadata": {},
   "source": [
    "#### BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0012621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sures\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Translating to Hindi...\n",
      "ğŸ” Translating to Tamil...\n",
      "ğŸ” Translating to Telugu...\n",
      "âœ… PDF saved for Hindi: Translated_Insurance_Policy_Hindi.pdf\n",
      "ğŸŸ¦ BLEU Score for Hindi: 0.0022\n",
      "âœ… PDF saved for Tamil: Translated_Insurance_Policy_Tamil.pdf\n",
      "ğŸŸ¦ BLEU Score for Tamil: 0.0027\n",
      "âœ… PDF saved for Telugu: Translated_Insurance_Policy_Telugu.pdf\n",
      "ğŸŸ¦ BLEU Score for Telugu: 0.0026\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from fpdf import FPDF\n",
    "import textwrap\n",
    "from googletrans import Translator\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download required tokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Constants\n",
    "FONT_PATH = \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSans-Regular.ttf\"\n",
    "FONT_FAMILY = \"NotoSans\"\n",
    "DEFAULT_LANGUAGE = \"Hindi\"\n",
    "\n",
    "# Supported languages\n",
    "SUPPORTED_LANGUAGES = {\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Tamil\": \"ta\",\n",
    "    \"Telugu\": \"te\",\n",
    "    \"Gujarati\": \"gu\",\n",
    "    \"Kannada\": \"kn\",\n",
    "    \"Bengali\": \"bn\",\n",
    "    \"Punjabi\": \"pa\",\n",
    "    \"Marathi\": \"mr\",\n",
    "    \"Malayalam\": \"ml\",\n",
    "    \"Urdu\": \"ur\",\n",
    "    \"Odia\": \"or\"\n",
    "}\n",
    "\n",
    "# Reference translations for BLEU score evaluation\n",
    "REFERENCE_TRANSLATIONS = {\n",
    "    \"Hindi\": \"à¤¯à¤¹ à¤à¤• à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤¬à¥€à¤®à¤¾ à¤ªà¥‰à¤²à¤¿à¤¸à¥€ à¤¹à¥ˆà¥¤\",\n",
    "    \"Tamil\": \"à®‡à®¤à¯ à®’à®°à¯ à®šà¯à®•à®¾à®¤à®¾à®° à®•à®¾à®ªà¯à®ªà¯€à®Ÿà¯à®Ÿà¯ à®•à¯Šà®³à¯à®•à¯ˆ.\",\n",
    "    \"Telugu\": \"à°‡à°¦à°¿ à°†à°°à±‹à°—à±à°¯ à°¬à±€à°®à°¾ à°ªà°¾à°²à°¸à±€.\"\n",
    "    # Add more human reference translations here as needed\n",
    "}\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")\n",
    "    return text\n",
    "\n",
    "# Step 2: Translate text\n",
    "def translate_text(text, target_languages):\n",
    "    translator = Translator()\n",
    "    translations = {}\n",
    "    for language in target_languages:\n",
    "        try:\n",
    "            lang_code = SUPPORTED_LANGUAGES[language]\n",
    "            print(f\"ğŸ” Translating to {language}...\")\n",
    "            translated = translator.translate(text, dest=lang_code)\n",
    "            translations[language] = translated.text\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error translating to {language}: {e}\")\n",
    "    return translations\n",
    "\n",
    "# Step 3: Unicode PDF generator\n",
    "class UnicodePDF(FPDF):\n",
    "    def __init__(self, font_path, font_family, title=\"\"):\n",
    "        super().__init__()\n",
    "        if not os.path.isfile(font_path):\n",
    "            raise RuntimeError(f\"âŒ Font file not found: {font_path}\")\n",
    "        self.font_family = font_family\n",
    "        self.title = title\n",
    "        self.add_font(font_family, '', font_path, uni=True)\n",
    "        self.add_page()\n",
    "        self.set_font(font_family, '', 12)\n",
    "        self.set_left_margin(10)\n",
    "        self.set_right_margin(10)\n",
    "\n",
    "    def header(self):\n",
    "        self.set_font(self.font_family, '', 16)\n",
    "        self.cell(0, 10, self.title, ln=True, align='C')\n",
    "        self.ln(10)\n",
    "        self.set_font(self.font_family, '', 12)\n",
    "\n",
    "    def add_multiline_text(self, text):\n",
    "        for paragraph in text.split(\"\\n\"):\n",
    "            wrapped = textwrap.fill(paragraph.strip(), width=90)\n",
    "            self.multi_cell(0, 8, wrapped)\n",
    "            self.ln(2)\n",
    "\n",
    "    def save(self, output_path):\n",
    "        self.output(output_path)\n",
    "\n",
    "# Step 4: Save translated PDF\n",
    "def create_unicode_pdf(translated_text, language, output_path):\n",
    "    try:\n",
    "        pdf = UnicodePDF(FONT_PATH, FONT_FAMILY, f\"Translated Insurance Policy - {language}\")\n",
    "        pdf.add_multiline_text(translated_text)\n",
    "        pdf.save(output_path)\n",
    "        print(f\"âœ… PDF saved for {language}: {output_path}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Step 5: Compute BLEU Score\n",
    "def compute_bleu(candidate_text, reference_text):\n",
    "    candidate_tokens = word_tokenize(candidate_text)\n",
    "    reference_tokens = [word_tokenize(reference_text)]\n",
    "    score = sentence_bleu(reference_tokens, candidate_tokens,\n",
    "                          weights=(0.25, 0.25, 0.25, 0.25),\n",
    "                          smoothing_function=SmoothingFunction().method4)\n",
    "    return score\n",
    "\n",
    "# Step 6: Main orchestrator\n",
    "def main(pdf_path, selected_languages):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    translations = translate_text(text, selected_languages)\n",
    "    \n",
    "    for language, translated_text in translations.items():\n",
    "        output_path = f\"Translated_Insurance_Policy_{language}.pdf\"\n",
    "        create_unicode_pdf(translated_text, language, output_path)\n",
    "\n",
    "        # BLEU score evaluation\n",
    "        reference_text = REFERENCE_TRANSLATIONS.get(language)\n",
    "        if reference_text:\n",
    "            bleu_score = compute_bleu(translated_text, reference_text)\n",
    "            print(f\"ğŸŸ¦ BLEU Score for {language}: {bleu_score:.4f}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ No reference translation found for {language}. Skipping BLEU score.\")\n",
    "\n",
    "# Step 7: Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    selected_languages = [\"Hindi\", \"Tamil\", \"Telugu\"]  # Choose from SUPPORTED_LANGUAGES\n",
    "    valid_languages = [lang for lang in selected_languages if lang in SUPPORTED_LANGUAGES]\n",
    "\n",
    "    if valid_languages:\n",
    "        pdf_path = \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Dataset/Health_Insurance_Policy.pdf\"\n",
    "        main(pdf_path, valid_languages)\n",
    "    else:\n",
    "        print(\"âŒ No valid languages selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d10395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sures\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import PyPDF2\n",
    "import re\n",
    "from googletrans import Translator\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import Paragraph, SimpleDocTemplate, Spacer, KeepTogether\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# ========== Font Mapping ==========\n",
    "language_fonts = {\n",
    "    \"en\": \"fonts/NotoSans-Regular.ttf\",\n",
    "    \"hi\": \"fonts/NotoSansDevanagari-Regular.ttf\",\n",
    "    \"ta\": \"fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"te\": \"fonts/NotoSansTelugu-Regular.ttf\"\n",
    "}\n",
    "\n",
    "# ========== BLEU Reference Translations ==========\n",
    "REFERENCE_TRANSLATIONS = {\n",
    "    \"Hindi\": \"à¤¯à¤¹ à¤à¤• à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤¬à¥€à¤®à¤¾ à¤ªà¥‰à¤²à¤¿à¤¸à¥€ à¤¹à¥ˆà¥¤\",\n",
    "    \"Tamil\": \"à®‡à®¤à¯ à®’à®°à¯ à®šà¯à®•à®¾à®¤à®¾à®° à®•à®¾à®ªà¯à®ªà¯€à®Ÿà¯à®Ÿà¯ à®•à¯Šà®³à¯à®•à¯ˆ.\",\n",
    "    \"Telugu\": \"à°‡à°¦à°¿ à°†à°°à±‹à°—à±à°¯ à°¬à±€à°®à°¾ à°ªà°¾à°²à°¸à±€.\"\n",
    "}\n",
    "\n",
    "# ========== Extract Text ==========\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        return \" \".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "\n",
    "# ========== Translate ==========\n",
    "def translate_text(text, lang_code):\n",
    "    translator = Translator()\n",
    "    return translator.translate(text, dest=lang_code).text\n",
    "\n",
    "# ========== Summarize ==========\n",
    "def summarize_text(text, sentences_count=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# ========== BLEU Score ==========\n",
    "def compute_bleu(candidate, reference):\n",
    "    candidate_tokens = word_tokenize(candidate)\n",
    "    reference_tokens = [word_tokenize(reference)]\n",
    "    return sentence_bleu(reference_tokens, candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25),\n",
    "                         smoothing_function=SmoothingFunction().method4)\n",
    "\n",
    "# ========== PDF Generation ==========\n",
    "def generate_pdf(text, font_path, output_path, title=\"Translated Insurance Policy\"):\n",
    "    font_name = os.path.splitext(os.path.basename(font_path))[0]\n",
    "    pdfmetrics.registerFont(TTFont(font_name, font_path))\n",
    "\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=A4,\n",
    "                            rightMargin=40, leftMargin=40,\n",
    "                            topMargin=60, bottomMargin=40)\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(name='Justify', fontName=font_name, fontSize=12, leading=16,\n",
    "                              alignment=TA_JUSTIFY, spaceAfter=10))\n",
    "\n",
    "    elements = [Paragraph(title, ParagraphStyle(name='Title', fontName=font_name, fontSize=16,\n",
    "                                                alignment=1, spaceAfter=20))]\n",
    "\n",
    "    normalized_text = re.sub(r'\\n+', '\\n', text)\n",
    "    normalized_text = re.sub(r'\\s{2,}', ' ', normalized_text)\n",
    "    paragraphs = [p.strip() for p in normalized_text.split('\\n') if len(p.strip()) > 20]\n",
    "\n",
    "    for para in paragraphs:\n",
    "        elements.append(KeepTogether([Paragraph(para, styles['Justify']), Spacer(1, 0.15 * inch)]))\n",
    "\n",
    "    doc.build(elements)\n",
    "\n",
    "# ========== Main Logic ==========\n",
    "def process_policy(pdf_path, selected_languages):\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(\"âŒ PDF not found.\")\n",
    "        return\n",
    "\n",
    "    print(\"ğŸ“„ Extracting text...\")\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    print(\"ğŸ§  Summarizing text...\")\n",
    "    english_summary = summarize_text(extracted_text)\n",
    "\n",
    "    print(\"\\nğŸ”¤ Summary in English:\\n\", english_summary)\n",
    "\n",
    "    for lang_name in selected_languages:\n",
    "        lang_code = {\n",
    "            \"Hindi\": \"hi\",\n",
    "            \"Tamil\": \"ta\",\n",
    "            \"Telugu\": \"te\"\n",
    "        }.get(lang_name)\n",
    "\n",
    "        if not lang_code:\n",
    "            print(f\"âš ï¸ Language '{lang_name}' not supported.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nğŸŒ Translating to {lang_name}...\")\n",
    "\n",
    "        translated_text = translate_text(extracted_text, lang_code)\n",
    "        translated_summary = translate_text(english_summary, lang_code)\n",
    "        full_translated_content = f\"{translated_summary}\\n\\n{translated_text}\"\n",
    "\n",
    "        # BLEU score (if reference available)\n",
    "        ref = REFERENCE_TRANSLATIONS.get(lang_name)\n",
    "        if ref:\n",
    "            bleu = compute_bleu(translated_text, ref)\n",
    "            print(f\"ğŸ”µ BLEU Score for {lang_name}: {bleu:.4f}\")\n",
    "        else:\n",
    "            print(f\"â„¹ï¸ No reference translation available for {lang_name}, skipping BLEU.\")\n",
    "\n",
    "        font_path = language_fonts[lang_code]\n",
    "        output_pdf = f\"Translated_Insurance_Policy_{lang_name}.pdf\"\n",
    "        generate_pdf(full_translated_content, font_path, output_pdf, title=f\"Insurance Policy - {lang_name}\")\n",
    "        print(f\"âœ… PDF saved: {output_pdf}\")\n",
    "\n",
    "# ========== Run ==========\n",
    "if __name__ == \"__main__\":\n",
    "    # Example\n",
    "    policy_path = \"Dataset/Health_Insurance_Policy.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469c2f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 41) (3150045508.py, line 41)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"Telugu\": \"à°‡à°¦à°¿ à°†à°°à±‹\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 41)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "import PyPDF2\n",
    "from googletrans import Translator\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import Paragraph, SimpleDocTemplate, Spacer, KeepTogether\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n",
    "from reportlab.lib.units import inch\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Font mapping per language code\n",
    "language_fonts = {\n",
    "    \"en\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSans-Regular.ttf\",\n",
    "    \"ta\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"hi\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansDevanagari-Regular.ttf\",\n",
    "    \"te\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTelugu-Regular.ttf\",\n",
    "    \"kn\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansKannada-Regular.ttf\",\n",
    "    \"ml\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansMalayalam-Regular.ttf\",\n",
    "    \"bn\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansBengali-Regular.ttf\",\n",
    "    \"gu\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansGujarati-Regular.ttf\",\n",
    "    \"ur\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansArabic-Regular.ttf\"\n",
    "}\n",
    "\n",
    "# Reference translations for BLEU evaluation\n",
    "REFERENCE_TRANSLATIONS = {\n",
    "    \"Hindi\": \"à¤¯à¤¹ à¤à¤• à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤¬à¥€à¤®à¤¾ à¤ªà¥‰à¤²à¤¿à¤¸à¥€ à¤¹à¥ˆà¥¤\",\n",
    "    \"Tamil\": \"à®‡à®¤à¯ à®’à®°à¯ à®šà¯à®•à®¾à®¤à®¾à®° à®•à®¾à®ªà¯à®ªà¯€à®Ÿà¯à®Ÿà¯à®¤à¯ à®¤à®¿à®Ÿà¯à®Ÿà®®à¯ à®ªà®±à¯à®±à®¿à®¯ à®†à®µà®£à®®à®¾à®•à¯à®®à¯.\",\n",
    "    \"Telugu\": \"à°‡à°¦à°¿ à°†à°°à±‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c733ba9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sures\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ English Summary:\n",
      "Coverage Summary This policy covers the following medical expenses: - Hospitalization (minimum 24 hours) - Pre-Hospitalization (30 days prior) - Post-Hospitalization (60 days post) - Daycare procedures (up to 500 listed procedures) - Emergency Ambulance (up to Rs.2,000 per hospitalization) - COVID-19 Treatment 3. Submit the following documents: - Discharge summary - Hospital bills - Doctor's prescription - ID proof 3. Renewal Terms - Policy must be renewed annually to avoid a lapse in coverage.\n",
      "\n",
      "ğŸ” Translating to Hindi...\n",
      "âœ… Saved PDF: Translated_Policies\\Translated_Insurance_Policy_Hindi.pdf\n",
      "ğŸ”µ BLEU Score for Hindi: 0.0051\n",
      "\n",
      "ğŸ” Translating to Tamil...\n",
      "âœ… Saved PDF: Translated_Policies\\Translated_Insurance_Policy_Tamil.pdf\n",
      "ğŸ”µ BLEU Score for Tamil: 0.0060\n",
      "\n",
      "ğŸ” Translating to Telugu...\n",
      "âœ… Saved PDF: Translated_Policies\\Translated_Insurance_Policy_Telugu.pdf\n",
      "ğŸ”µ BLEU Score for Telugu: 0.0056\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "import PyPDF2\n",
    "from googletrans import Translator\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import Paragraph, SimpleDocTemplate, Spacer, KeepTogether\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n",
    "from reportlab.lib.units import inch\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Font mapping per language code\n",
    "language_fonts = {\n",
    "    \"en\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSans-Regular.ttf\",\n",
    "    \"ta\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"hi\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansDevanagari-Regular.ttf\",\n",
    "    \"te\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTelugu-Regular.ttf\",\n",
    "    \"kn\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansKannada-Regular.ttf\",\n",
    "    \"ml\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansMalayalam-Regular.ttf\",\n",
    "    \"bn\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansBengali-Regular.ttf\",\n",
    "    \"gu\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansGujarati-Regular.ttf\",\n",
    "    \"ur\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansArabic-Regular.ttf\"\n",
    "}\n",
    "\n",
    "# Reference translations for BLEU evaluation\n",
    "REFERENCE_TRANSLATIONS = {\n",
    "    \"Hindi\": \"à¤¯à¤¹ à¤à¤• à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤¬à¥€à¤®à¤¾ à¤ªà¥‰à¤²à¤¿à¤¸à¥€ à¤¹à¥ˆà¥¤\",\n",
    "    \"Tamil\": \"à®‡à®¤à¯ à®’à®°à¯ à®šà¯à®•à®¾à®¤à®¾à®° à®•à®¾à®ªà¯à®ªà¯€à®Ÿà¯à®Ÿà¯à®¤à¯ à®¤à®¿à®Ÿà¯à®Ÿà®®à¯ à®ªà®±à¯à®±à®¿à®¯ à®†à®µà®£à®®à®¾à®•à¯à®®à¯.\",\n",
    "    \"Telugu\": \"à°‡à°¦à°¿ à°†à°°à±‹à°—à±à°¯ à°¬à±€à°®à°¾ à°ªà°¾à°²à°¸à±€à°•à°¿ à°¸à°‚à°¬à°‚à°§à°¿à°‚à°šà°¿à°¨ à°¡à°¾à°•à±à°¯à±à°®à±†à°‚à°Ÿà±.\"\n",
    "}\n",
    "\n",
    "language_map = {\n",
    "    \"English\": \"en\",\n",
    "    \"Tamil\": \"ta\",\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Telugu\": \"te\",\n",
    "    \"Kannada\": \"kn\",\n",
    "    \"Malayalam\": \"ml\",\n",
    "    \"Bengali\": \"bn\",\n",
    "    \"Gujarati\": \"gu\",\n",
    "    \"Urdu\": \"ur\",\n",
    "}\n",
    "\n",
    "# Extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = ''.join(page.extract_text() or \"\" for page in reader.pages)\n",
    "    return text\n",
    "\n",
    "# Translate text\n",
    "def translate_text(text, dest_language):\n",
    "    translator = Translator()\n",
    "    return translator.translate(text, dest=dest_language).text\n",
    "\n",
    "# Summarize text\n",
    "def summarize_text(text, language=\"english\", sentences_count=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return ' '.join(str(sentence) for sentence in summary)\n",
    "\n",
    "# Generate PDF\n",
    "def generate_translated_pdf(text, font_path, output_path, lang_title=\"Translated Insurance Policy\"):\n",
    "    font_name = os.path.splitext(os.path.basename(font_path))[0]\n",
    "    pdfmetrics.registerFont(TTFont(font_name, font_path))\n",
    "\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=A4,\n",
    "                            rightMargin=40, leftMargin=40, topMargin=60, bottomMargin=40)\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(name='Justify', fontName=font_name, fontSize=12,\n",
    "                              leading=16, alignment=TA_JUSTIFY, spaceAfter=10))\n",
    "\n",
    "    elements = []\n",
    "\n",
    "    title_style = ParagraphStyle(name='Title', fontName=font_name, fontSize=16, alignment=1, spaceAfter=20)\n",
    "    elements.append(Paragraph(lang_title, title_style))\n",
    "\n",
    "    normalized_text = re.sub(r'\\n+', '\\n', text)\n",
    "    normalized_text = re.sub(r'\\s{2,}', ' ', normalized_text)\n",
    "    paragraphs = [p.strip() for p in normalized_text.split('\\n') if len(p.strip()) > 20]\n",
    "\n",
    "    for para in paragraphs:\n",
    "        elements.append(KeepTogether([\n",
    "            Paragraph(para, styles['Justify']),\n",
    "            Spacer(1, 0.15 * inch)\n",
    "        ]))\n",
    "\n",
    "    doc.build(elements)\n",
    "\n",
    "# Compute BLEU score\n",
    "def compute_bleu(candidate, reference):\n",
    "    reference_tokens = word_tokenize(reference)\n",
    "    candidate_tokens = word_tokenize(candidate)\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoothie)\n",
    "\n",
    "# Main processing function\n",
    "def process_policy_pdf(pdf_path, selected_languages):\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "    print(\"\\nğŸ“ English Summary:\")\n",
    "    english_summary = summarize_text(extracted_text)\n",
    "    print(english_summary)\n",
    "\n",
    "    for lang_name in selected_languages:\n",
    "        lang_code = language_map.get(lang_name)\n",
    "        if not lang_code:\n",
    "            print(f\"\\nâŒ Skipping unsupported language: {lang_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nğŸ” Translating to {lang_name}...\")\n",
    "        translated_text = translate_text(extracted_text, lang_code)\n",
    "        translated_summary = translate_text(english_summary, lang_code)\n",
    "        full_translated = f\"{translated_summary}\\n\\n{translated_text}\"\n",
    "\n",
    "        font_path = language_fonts.get(lang_code, language_fonts['en'])\n",
    "        os.makedirs(\"Translated_Policies\", exist_ok=True)\n",
    "        output_path = os.path.join(\"Translated_Policies\", f\"Translated_Insurance_Policy_{lang_name}.pdf\")\n",
    "        generate_translated_pdf(full_translated, font_path, output_path, f\"Translated Insurance Policy ({lang_name})\")\n",
    "\n",
    "        print(f\"âœ… Saved PDF: {output_path}\")\n",
    "\n",
    "        # BLEU score\n",
    "        ref = REFERENCE_TRANSLATIONS.get(lang_name)\n",
    "        if ref:\n",
    "            bleu = compute_bleu(translated_summary, ref)\n",
    "            print(f\"ğŸ”µ BLEU Score for {lang_name}: {bleu:.4f}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ No reference translation for BLEU in {lang_name}.\")\n",
    "\n",
    "# Run example\n",
    "if __name__ == \"__main__\":\n",
    "    sample_pdf = \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Dataset/Health_Insurance_Policy.pdf\"\n",
    "    selected_languages = [\"Hindi\", \"Tamil\", \"Telugu\"]\n",
    "    process_policy_pdf(sample_pdf, selected_languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36154f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sures\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Extracting text from PDF...\n",
      "\n",
      "ğŸ“ English Summary:\n",
      "Coverage Summary This policy covers the following medical expenses: - Hospitalization (minimum 24 hours) - Pre-Hospitalization (30 days prior) - Post-Hospitalization (60 days post) - Daycare procedures (up to 500 listed procedures) - Emergency Ambulance (up to Rs.2,000 per hospitalization) - COVID-19 Treatment 3. Submit the following documents: - Discharge summary - Hospital bills - Doctor's prescription - ID proof 3. Renewal Terms - Policy must be renewed annually to avoid a lapse in coverage.\n",
      "\n",
      "ğŸ” Translating to Hindi...\n",
      "âœ… Saved PDF: Translated_Policies/Translated_Insurance_Policy_Hindi.pdf\n",
      "ğŸ”µ BLEU Score for Hindi: 0.3292\n",
      "\n",
      "ğŸ” Translating to Tamil...\n",
      "âœ… Saved PDF: Translated_Policies/Translated_Insurance_Policy_Tamil.pdf\n",
      "ğŸ”µ BLEU Score for Tamil: 0.2734\n",
      "\n",
      "ğŸ” Translating to Telugu...\n",
      "âœ… Saved PDF: Translated_Policies/Translated_Insurance_Policy_Telugu.pdf\n",
      "ğŸ”µ BLEU Score for Telugu: 0.2416\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from googletrans import Translator\n",
    "from PyPDF2 import PdfReader\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import Paragraph, SimpleDocTemplate, Spacer, KeepTogether\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Fonts\n",
    "language_fonts = {\n",
    "    \"en\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"hi\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"ta\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"te\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "}\n",
    "\n",
    "language_map = {\n",
    "    \"English\": \"en\",\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Tamil\": \"ta\",\n",
    "    \"Telugu\": \"te\",\n",
    "}\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        pdf = PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "# Step 2: Summarize text\n",
    "def summarize_text(text, language=\"english\", sentences_count=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# Step 3: Translate text\n",
    "def translate_text(text, target_lang):\n",
    "    translator = Translator()\n",
    "    return translator.translate(text, dest=target_lang).text\n",
    "\n",
    "# Step 4: Back-translate to English\n",
    "def back_translate(text, src_lang):\n",
    "    translator = Translator()\n",
    "    return translator.translate(text, src='auto', dest='en').text\n",
    "\n",
    "# Step 5: Generate aligned PDF\n",
    "def generate_pdf(text, font_path, output_path, title=\"Translated Insurance Policy\"):\n",
    "    font_name = os.path.splitext(os.path.basename(font_path))[0]\n",
    "    pdfmetrics.registerFont(TTFont(font_name, font_path))\n",
    "    \n",
    "    doc = SimpleDocTemplate(output_path, pagesize=A4, rightMargin=40, leftMargin=40, topMargin=60, bottomMargin=40)\n",
    "    styles = getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(\n",
    "        name='Justify',\n",
    "        fontName=font_name,\n",
    "        fontSize=12,\n",
    "        leading=16,\n",
    "        alignment=TA_JUSTIFY,\n",
    "        spaceAfter=10\n",
    "    ))\n",
    "\n",
    "    elements = []\n",
    "    elements.append(Paragraph(title, ParagraphStyle(name='Title', fontName=font_name, fontSize=16, alignment=1, spaceAfter=20)))\n",
    "    \n",
    "    clean_text = re.sub(r'\\n+', '\\n', text)\n",
    "    paragraphs = [p.strip() for p in clean_text.split('\\n') if len(p.strip()) > 20]\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        elements.append(KeepTogether([Paragraph(para, styles['Justify']), Spacer(1, 0.15 * inch)]))\n",
    "    \n",
    "    doc.build(elements)\n",
    "\n",
    "# Step 6: Compute BLEU Score\n",
    "def compute_bleu(reference_text, translated_back_text):\n",
    "    reference_tokens = nltk.word_tokenize(reference_text.lower())\n",
    "    translated_tokens = nltk.word_tokenize(translated_back_text.lower())\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    score = sentence_bleu([reference_tokens], translated_tokens, smoothing_function=smoothie)\n",
    "    return score\n",
    "\n",
    "# Main Process\n",
    "def main():\n",
    "    input_pdf = \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Dataset/Health_Insurance_Policy.pdf\"\n",
    "    selected_languages = [\"Hindi\", \"Tamil\", \"Telugu\"]\n",
    "\n",
    "    print(\"ğŸ” Extracting text from PDF...\")\n",
    "    extracted_text = extract_text_from_pdf(input_pdf)\n",
    "\n",
    "    print(\"\\nğŸ“ English Summary:\")\n",
    "    summary = summarize_text(extracted_text)\n",
    "    print(summary)\n",
    "\n",
    "    for lang in selected_languages:\n",
    "        lang_code = language_map[lang]\n",
    "        font_path = language_fonts[lang_code]\n",
    "\n",
    "        print(f\"\\nğŸ” Translating to {lang}...\")\n",
    "        translated = translate_text(summary, lang_code)\n",
    "        translated_pdf_path = f\"Translated_Policies/Translated_Insurance_Policy_{lang}.pdf\"\n",
    "        os.makedirs(\"Translated_Policies\", exist_ok=True)\n",
    "\n",
    "        full_text = f\"{translated}\\n\\n{extracted_text}\"\n",
    "        generate_pdf(full_text, font_path, translated_pdf_path, title=f\"Translated Insurance Policy ({lang})\")\n",
    "        print(f\"âœ… Saved PDF: {translated_pdf_path}\")\n",
    "\n",
    "        # Back-translate and calculate BLEU\n",
    "        translated_back = back_translate(translated, lang_code)\n",
    "        bleu = compute_bleu(summary, translated_back)\n",
    "        print(f\"ğŸ”µ BLEU Score for {lang}: {bleu:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f648510",
   "metadata": {},
   "source": [
    "#### ROUGE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d69cfa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: nltk in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\ai-powered intelligent insurance risk assessment and customer insights system\\env\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (pyproject.toml): started\n",
      "  Building wheel for rouge_score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=25027 sha256=1e711cb1b7cd181778527015cd3faa4d1ce8ed439db89857a7a28497dde4f405\n",
      "  Stored in directory: c:\\users\\sures\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: absl-py, rouge_score\n",
      "Successfully installed absl-py-2.2.2 rouge_score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "536e2af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Extracting text from PDF...\n",
      "\n",
      "ğŸ“ English Summary:\n",
      "Coverage Summary This policy covers the following medical expenses: - Hospitalization (minimum 24 hours) - Pre-Hospitalization (30 days prior) - Post-Hospitalization (60 days post) - Daycare procedures (up to 500 listed procedures) - Emergency Ambulance (up to Rs.2,000 per hospitalization) - COVID-19 Treatment 3. Submit the following documents: - Discharge summary - Hospital bills - Doctor's prescription - ID proof 3. Renewal Terms - Policy must be renewed annually to avoid a lapse in coverage.\n",
      "\n",
      "ğŸ” Translating to Hindi...\n",
      "âœ… Saved PDF: Translated_Policies/Translated_Insurance_Policy_Hindi.pdf\n",
      "ğŸ”µ ROUGE Score for Hindi:\n",
      " ROUGE-1: Score(precision=0.8095238095238095, recall=0.4857142857142857, fmeasure=0.6071428571428571)\n",
      " ROUGE-2: Score(precision=0.6341463414634146, recall=0.37681159420289856, fmeasure=0.4727272727272728)\n",
      " ROUGE-L: Score(precision=0.7857142857142857, recall=0.4714285714285714, fmeasure=0.5892857142857143)\n",
      "\n",
      "ğŸ” Translating to Tamil...\n",
      "âœ… Saved PDF: Translated_Policies/Translated_Insurance_Policy_Tamil.pdf\n",
      "ğŸ”µ ROUGE Score for Tamil:\n",
      " ROUGE-1: Score(precision=0.7692307692307693, recall=0.42857142857142855, fmeasure=0.5504587155963303)\n",
      " ROUGE-2: Score(precision=0.631578947368421, recall=0.34782608695652173, fmeasure=0.4485981308411215)\n",
      " ROUGE-L: Score(precision=0.7692307692307693, recall=0.42857142857142855, fmeasure=0.5504587155963303)\n",
      "\n",
      "ğŸ” Translating to Telugu...\n",
      "âœ… Saved PDF: Translated_Policies/Translated_Insurance_Policy_Telugu.pdf\n",
      "ğŸ”µ ROUGE Score for Telugu:\n",
      " ROUGE-1: Score(precision=0.875, recall=0.4, fmeasure=0.5490196078431373)\n",
      " ROUGE-2: Score(precision=0.6774193548387096, recall=0.30434782608695654, fmeasure=0.42)\n",
      " ROUGE-L: Score(precision=0.84375, recall=0.38571428571428573, fmeasure=0.5294117647058824)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "from nltk.tokenize import word_tokenize\n",
    "from googletrans import Translator\n",
    "from rouge_score import rouge_scorer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from PyPDF2 import PdfReader\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import Paragraph, SimpleDocTemplate, Spacer, KeepTogether\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "# Fonts mapping\n",
    "language_fonts = {\n",
    "    \"en\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"hi\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"ta\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "    \"te\": \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/fonts/NotoSansTamil-Regular.ttf\",\n",
    "}\n",
    "\n",
    "# Language code mapping\n",
    "language_map = {\n",
    "    \"English\": \"en\",\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Tamil\": \"ta\",\n",
    "    \"Telugu\": \"te\",\n",
    "}\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        pdf = PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "# Step 2: Summarize text\n",
    "def summarize_text(text, language=\"english\", sentences_count=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# Step 3: Translate text\n",
    "def translate_text(text, target_lang):\n",
    "    translator = Translator()\n",
    "    return translator.translate(text, dest=target_lang).text\n",
    "\n",
    "# Step 4: Back-translate to English\n",
    "def back_translate(text, src_lang):\n",
    "    translator = Translator()\n",
    "    return translator.translate(text, src='auto', dest='en').text\n",
    "\n",
    "# Step 5: Generate PDF\n",
    "def generate_pdf(text, font_path, output_path, title=\"Translated Insurance Policy\"):\n",
    "    font_name = os.path.splitext(os.path.basename(font_path))[0]\n",
    "    pdfmetrics.registerFont(TTFont(font_name, font_path))\n",
    "    \n",
    "    doc = SimpleDocTemplate(output_path, pagesize=A4, rightMargin=40, leftMargin=40, topMargin=60, bottomMargin=40)\n",
    "    styles = getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(\n",
    "        name='Justify',\n",
    "        fontName=font_name,\n",
    "        fontSize=12,\n",
    "        leading=16,\n",
    "        alignment=TA_JUSTIFY,\n",
    "        spaceAfter=10\n",
    "    ))\n",
    "\n",
    "    elements = []\n",
    "    elements.append(Paragraph(title, ParagraphStyle(name='Title', fontName=font_name, fontSize=16, alignment=1, spaceAfter=20)))\n",
    "    \n",
    "    clean_text = re.sub(r'\\n+', '\\n', text)\n",
    "    paragraphs = [p.strip() for p in clean_text.split('\\n') if len(p.strip()) > 20]\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        elements.append(KeepTogether([Paragraph(para, styles['Justify']), Spacer(1, 0.15 * inch)]))\n",
    "    \n",
    "    doc.build(elements)\n",
    "\n",
    "# Step 6: Compute ROUGE Score\n",
    "def compute_rouge(reference_text, translated_back_text):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_text, translated_back_text)\n",
    "    return scores\n",
    "\n",
    "# Main Process\n",
    "def main():\n",
    "    input_pdf = \"D:/AI-Powered Intelligent Insurance Risk Assessment and Customer Insights System/Dataset/Health_Insurance_Policy.pdf\"\n",
    "    selected_languages = [\"Hindi\", \"Tamil\", \"Telugu\"]\n",
    "\n",
    "    print(\"ğŸ” Extracting text from PDF...\")\n",
    "    extracted_text = extract_text_from_pdf(input_pdf)\n",
    "\n",
    "    print(\"\\nğŸ“ English Summary:\")\n",
    "    summary = summarize_text(extracted_text)\n",
    "    print(summary)\n",
    "\n",
    "    for lang in selected_languages:\n",
    "        lang_code = language_map[lang]\n",
    "        font_path = language_fonts[lang_code]\n",
    "\n",
    "        print(f\"\\nğŸ” Translating to {lang}...\")\n",
    "        translated = translate_text(summary, lang_code)\n",
    "        translated_pdf_path = f\"Translated_Policies/Translated_Insurance_Policy_{lang}.pdf\"\n",
    "        os.makedirs(\"Translated_Policies\", exist_ok=True)\n",
    "\n",
    "        full_text = f\"{translated}\\n\\n{extracted_text}\"\n",
    "        generate_pdf(full_text, font_path, translated_pdf_path, title=f\"Translated Insurance Policy ({lang})\")\n",
    "        print(f\"âœ… Saved PDF: {translated_pdf_path}\")\n",
    "\n",
    "        # Back-translate and calculate ROUGE\n",
    "        translated_back = back_translate(translated, lang_code)\n",
    "        rouge_scores = compute_rouge(summary, translated_back)\n",
    "        \n",
    "        print(f\"ğŸ”µ ROUGE Score for {lang}:\")\n",
    "        print(f\" ROUGE-1: {rouge_scores['rouge1']}\")\n",
    "        print(f\" ROUGE-2: {rouge_scores['rouge2']}\")\n",
    "        print(f\" ROUGE-L: {rouge_scores['rougeL']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285e94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
